---
title: "score_prediction"
author: "Chhiring Lama"
date: "2024-12-15"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE)
library(PerformanceAnalytics)
library(rstatix)
library(gtools)
library(tidyverse)
library(ggplot2)
library(caret)
library(ggpubr)
library(dplyr)

knitr::opts_chunk$set(
	include = TRUE,
	warning = FALSE,
	fig.width = 7, 
  fig.height = 5,
  out.width = "90%", 
	fig.align = "center"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal())
```

```{r, include=FALSE}
score_df <- read_csv("Project_1_data.csv") |>  
  janitor::clean_names() |>  
  mutate(wkly_study_hours = 
           case_match(
             wkly_study_hours, 
             "< 5" ~ "< 5",
             "> 10" ~ "> 10", 
             "10-May" ~ "5-10"), 
         wkly_study_hours = factor(wkly_study_hours, c("< 5", "5-10", "> 10")), 
         lunch_type = fct_relevel(lunch_type, "standard"), 
         parent_marital_status = fct_relevel(parent_marital_status, "single"), 
         transport_means = fct_relevel(transport_means, "school_bus"), 
         parent_educ = fct_relevel(parent_educ, "some high school"))
```

Firstly, we were interested in identifying any covariates are associated with each other or not. There are ten categorical potential predictors for which we first tested for chi-squared test for each pair of two variables. However, there wasn't enough evidence suggesting association between any two categorical variables.
```{r}
cat_columns <- names(score_df)[c(1:8, 10:11)]
comparisons <- combn(cat_columns, 2, simplify = FALSE)

categorical_df <- score_df[, cat_columns] |> 
  drop_na()
  
chiseq_test <- lapply(comparisons, function(x){
  categorical_df <- score_df |> 
    dplyr::select(x[1], x[2]) |> 
    drop_na()
  res = chisq.test(table(categorical_df), 
                   correct = TRUE) |> 
    broom::tidy() |> 
    mutate(group = paste(x[1], x[2], sep = ":"), 
           `p.value` = signif(`p.value`, 3), 
           statistic = round(statistic, 3))
  
  return(res)
})

chiseq_test <- bind_rows(chiseq_test) 

chiseq_test |> 
  dplyr::select(statistic, `p.value`, group) |> 
  arrange(`p.value`) |> 
  head(5) |> 
  knitr::kable(caption = "Chi-Squared Test For Categorical Covariates: Top 5 results (No signficant associations)")
```

Next, the remaining continuous variable, `nr_siblings`, that measure number of siblings was tested against all the categorical variables to test for number of sibling differs between different categorical variables. Number of siblings were different between students who were the first child versus those who were not, also between students with different number of weekly study hours. It will be worth accounting for both `is_first_child` and `wkly_study_hours` if we include number of siblings in the model.  
```{r}
grouped_df <- score_df |> 
      pivot_longer(
        cols = c(1:8, 10:11), 
        names_to = "cat_group", 
        values_to = "cat_val") |> 
  drop_na() 

grouped_df |> 
  ggplot(aes(x = cat_val, y = nr_siblings, fill = cat_group)) +
  geom_boxplot(alpha = 0.6) + 
  labs(y = "Number of Siblings") +
  coord_flip() +
  facet_wrap(~cat_group, scales = "free", ncol = 3) +
  theme_minimal()+
  theme(legend.position = "none") 
```

```{r}
aov_res <- lapply(cat_columns, function(category){
  res = aov(nr_siblings ~ get(category), 
                    data = score_df) |> 
    broom::tidy() |> 
    mutate(term = case_when(
      term == "get(category)" ~ category, 
      TRUE ~ term)) |> 
    slice(1) |> 
    dplyr::select(term, df, statistic, `p.value`)
  return(res)
})

aov_res <- bind_rows(aov_res) 

aov_res |> 
  filter(`p.value` < 0.05) |> 
  mutate(`p.value` = signif(`p.value`, 3), 
         statistic = round(statistic, digits = 3)) |> 
  knitr::kable()
```

To model for math, reading and writing scores of students, we utilized step-wise regression validation process for model selection. 


```{r, include = FALSE}
math_model1v1 <- lm(math_score ~ gender + wkly_study_hours + test_prep + nr_siblings, data = score_df)
summary(math_model1v1) 

### number of siblings not important
```

```{r, fig.caps = "Preliminary model 1 for Math Score"}
math_model1 <- lm(math_score+1 ~ gender + wkly_study_hours + test_prep + ethnic_group + lunch_type, data = score_df) 

par(mfrow = c(2,2))
plot(math_model1)
shapiro.test(rstandard(math_model1))

par(mfrow = c(1,1))
boxcox <- MASS::boxcox(math_model1, 
             lambda = seq(-2.5, 2.5, 1/10)) 

boxcox <- Reduce(cbind, boxcox)
optimal_power <- boxcox |> 
  as_tibble() |> 
  filter(V2 == max(V2)) |> 
  pull(init) |> 
  round(digits =2)
```
The residuals perfectly don't fit the Y=X line, and the variance is slightly higher in lower predicted math score ($\hat{Y_i}$). 

Transforming Y: 
```{r}
score_df <- score_df |> 
  mutate(transformed_math = (math_score +1)^1.29)
math_model1 <- lm(transformed_math ~ gender + wkly_study_hours + test_prep + ethnic_group + lunch_type, data = score_df) 

math_model1 |> 
  broom::tidy() |> 
  mutate(`p.value` = signif(`p.value`, 3), 
         estimate = round(estimate, 3), 
         `std.error` = round(`std.error`, 3), 
         statistic = round(statistic, 3)) |> 
  knitr::kable(digits = 50)

par(mfrow = c(2,2))
plot(math_model1)
shapiro.test(rstandard(math_model1))

### removing the influential point if needed
cooksd <- cooks.distance(math_model1)
influential <- as.numeric(names(cooksd)[(cooksd > 0.5)])
```

As seen above the after Y transformation where $Y^*= ({math\_score + 1})^{1.34}$, the residuals follow normality, homoscedascity and mean zero looking at the diagnostic plots. 


```{r, include = FALSE}
### do gender and wkly study hour/test_prep/ethnic_group have combined effect?
math_model2v1 <- lm(transformed_math ~ gender*wkly_study_hours + gender*test_prep + gender*ethnic_group + gender*lunch_type, data = score_df)
summary(math_model2v1)

### no significant interaction effect and adjusted R^2 decreasing so, not choosing these interactions

### how about interaction of test prep with weekly study hours and ethnic_group
math_model2v2 <- lm(transformed_math ~ gender + wkly_study_hours*test_prep*ethnic_group*lunch_type, data = score_df)
summary(math_model2v2)

### no significant interaction effect and adjusted R^2 decreasing so, not choosing these interactions

math_model2v3 <- lm(transformed_math ~ gender + wkly_study_hours + test_prep + ethnic_group + lunch_type + parent_educ, data = score_df)
summary(math_model2v3)
```

```{r}
math_model2 <- lm(transformed_math ~ gender + wkly_study_hours + test_prep + ethnic_group + lunch_type + parent_educ, data = score_df) 
math_model2 |> 
  broom::tidy() |> 
  mutate(`p.value` = signif(`p.value`, 3), 
         estimate = round(estimate, 3), 
         `std.error` = round(`std.error`, 3), 
         statistic = round(statistic, 3)) |> 
  knitr::kable(digits = 50)

par(mfrow = c(2,2))
plot(math_model2)

### removing the influential point if needed
cooksd <- cooks.distance(math_model2)
influential <- as.numeric(names(cooksd)[(cooksd > 0.5)])

```

```{r, include = FALSE}
### adding parents education improved adjusted R and it is signficant

### testing parent's education's interaction with others
math_model3v1 <- lm(transformed_math ~ gender*parent_educ + wkly_study_hours*parent_educ + test_prep*parent_educ + ethnic_group*parent_educ, data = score_df)
summary(math_model3v1)

### no significant interaction effect and adjusted R^2 decreased so, not choosing this

### adding interactions for parental marital status
math_model3v2 <- lm(transformed_math ~ gender + wkly_study_hours*parent_marital_status + test_prep*parent_marital_status + ethnic_group*parent_marital_status + lunch_type*parent_marital_status + parent_educ*parent_marital_status, data = score_df)
summary(math_model3v2)

### adding sports practice status
math_model3v3 <- lm(transformed_math ~ gender + wkly_study_hours*parent_marital_status + test_prep + ethnic_group + lunch_type + parent_educ*parent_marital_status + practice_sport, data = score_df)
summary(math_model3v3)

```

```{r}
math_model3 <- lm(transformed_math ~ gender + wkly_study_hours*parent_marital_status + test_prep + ethnic_group + lunch_type + parent_educ*parent_marital_status + practice_sport, data = score_df)

math_model3 |> 
  broom::tidy() |> 
  mutate(`p.value` = signif(`p.value`, 3), 
         estimate = round(estimate, 3), 
         `std.error` = round(`std.error`, 3), 
         statistic = round(statistic, 3)) |> 
  knitr::kable(digits = 50)

par(mfrow = c(2,2))
plot(math_model3)

### removing the influential point if needed
cooksd <- cooks.distance(math_model3)
influential <- as.numeric(names(cooksd)[(cooksd > 0.5)])
```


```{r, include = FALSE}
### adding transport means
math_model4v1 <- lm(transformed_math ~ gender + wkly_study_hours*parent_marital_status + test_prep + ethnic_group + lunch_type + parent_educ*parent_marital_status + transport_means, data = score_df)
summary(math_model4v1)

### transportation was not important so going back

### adding is_first_child
math_model4v2 <- lm(transformed_math ~ gender + wkly_study_hours*parent_marital_status + test_prep + ethnic_group + lunch_type + parent_educ*parent_marital_status + is_first_child, data = score_df)
summary(math_model4v2)

### first child was not important so going back
### will test math_model1, math_model2 and math_model3
```

After testing multiple models and removing redundant predictors using step-wise regression, the three models with higher adjusted $R^2$ are selected further for cross-validation to pick the best predictive model. Here is a look to the 5-fold division for cross-validation. 

## Splitting dataset for cross validation
```{r, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 4, out.width = "95%", dpi = 600}
#specify the cross-validation method
set.seed(1)
ctrl <- trainControl(method = "cv", number = 5)

filtered_df <- score_df |> 
  drop_na(gender, wkly_study_hours, parent_marital_status, test_prep, ethnic_group, 
          lunch_type, parent_educ, practice_sport)

#fit a regression model and use k-fold CV to evaluate performance
model1 <- train(transformed_math ~ gender + wkly_study_hours + 
    test_prep + ethnic_group + lunch_type, data = filtered_df, method = "lm", trControl = ctrl)

model2 <- train(transformed_math ~ gender + wkly_study_hours + 
    test_prep + ethnic_group + lunch_type + parent_educ, data = filtered_df, method = "lm", trControl = ctrl)

model3 <- train(transformed_math ~ gender + wkly_study_hours*parent_marital_status + test_prep + ethnic_group + lunch_type + 
    parent_educ*parent_marital_status + practice_sport, data = filtered_df, method = "lm", trControl = ctrl)
# get fold subsets
fold_data_model1 <- lapply(model1$control$index, function(index) filtered_df[index,]) |> 
    bind_rows(.id = "Fold") 
fold_data_model2 <- lapply(model2$control$index, function(index) filtered_df[index,]) |> 
    bind_rows(.id = "Fold") 
fold_data_model3 <- lapply(model3$control$index, function(index) filtered_df[index,]) |> 
    bind_rows(.id = "Fold") 

# example plots
plot1 <- ggplot(fold_data_model1, aes(math_score, col = Fold)) + geom_density(alpha = 0.6) + ggtitle("Model1")
plot2 <- ggplot(fold_data_model2, aes(math_score, col = Fold)) + geom_density(alpha = 0.6) + ggtitle("Model2")
plot3 <- ggplot(fold_data_model3, aes(math_score, col = Fold)) + geom_density(alpha = 0.6) + ggtitle("Model3")
ggarrange(plot1, plot2, plot3, ncol = 3, common.legend = TRUE)
```

Below is the 5-fold cross-validation results including fitted value versus observed score plot and performace metrices from each of the three models. 
```{r, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 4, out.width = "95%", dpi = 600}
filtered_df |> 
  mutate(math_model1_pred = (model1[["finalModel"]][["fitted.values"]])^(1/1.29) - 1, 
         math_model2_pred = (model2[["finalModel"]][["fitted.values"]])^(1/1.29) - 1, 
         math_model3_pred = (model3[["finalModel"]][["fitted.values"]])^(1/1.29) - 1) |> 
  pivot_longer(
    cols = c(math_model1_pred, math_model2_pred, math_model3_pred), 
    names_to = "model_type", 
    values_to = "res"
  ) |> 
  ggplot(aes(x = res, y = math_score)) +
  geom_abline(intercept = 0, slope = 1, color = "#f7aa58") +
  geom_point(size = 1, shape = 21) +
  facet_wrap(~model_type, scale = "free") +
  stat_cor(label.y = 5) +
  scale_x_discrete(labels = c("Predicted Math Score"))

bind_rows(model1$results, model2$results, model3$results) |> 
  mutate(model_id = c(1, 2, 3)) |> 
  relocate(model_id) |> 
  knitr::kable(digits =3, caption = "Performance matrices of the 3 Multiple Linear Regression Models")

```







